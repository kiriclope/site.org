<!DOCTYPE html>
<html lang="en">
<head>
<!-- 07 Jan. 2026 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Fine-tuning GPT with openai API</title>
<meta name="generator" content="Org mode">
<meta name="author" content="Alexandre Mahrach">
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-1687066-2"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-1687066-2');
</script>
<link href='https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css' rel='stylesheet' integrity='crossorigin' anonymous='nil'/>
<meta description='The blog of Alexandre Mahrach'/>
<link rel='alternate' type='application+rss/xml' title='The blog of Alexandre Mahrach' href='posts/rss.xml'/>
<link rel="stylesheet" href="../../css/site.css?v=dfffad2303a13cebe8e9e438d5bc7ec92d5b18b4645dffec15113add46770f42" type="text/css">
</head>
<body>
<header id="preamble" class="status">
<div class="logo">
  <a href="/">
    <img src="/images/photo.png" class="avatar" alt="My photo"/>
  </a>
  <div class="title-section">
    <a href="/"><h1>Alexandre Mahrach</h1></a>
    <!-- <sub style="line-height:1;"> <h2>Data Scientist & Machine Learning Expert</h2> </sub> -->
    <nav>
      <ul>
        <li><a href="/news.html"> News </a></li>
        <li><a href="/posts/archive.html"> Posts </a></li>
        <li><a href="/tutorials/tutorials.html"> Tutorials </a></li>
        <li><a href="/about.html"> About </a></li>
        <!-- add more as needed -->
      </ul>
    </nav>
  </div>
  <div id="social">
    <a title="kiriclope on Github" href="https://github.com/kiriclope">
      <i class="fa-brands fa-github"></i>
    </a>
    <a title="amahrach on LinkedIn" href="https://linkedin.com/in/amahrach">
      <i class="fa-brands fa-linkedin"></i>
    </a>
    <!-- <a title="dmacvicar on Twitter" href="https://twitter.com/dmacvicar"> -->
      <!--   <i class="fa-brands fa-twitter"></i> -->
      <!-- </a> -->
    <a title="RSS feed" id="atom" href="posts/rss.xml">
      <i class="fa-solid fa-rss"></i>
    </a>
  </div>
</div>

<script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script>
<script>
  function addDarkmodeWidget() {
    new Darkmode({
      bottom: 'unset', // Remove bottom positioning
      right: '10px', // Remove default right positioning
      left: 'unset', // Remove default left positioning
      label: 'ðŸŒ“', // Custom label/icon
      time: '0.5s', // Transition time
      autoMatchOsTheme: false, // Disable automatic theme matching based on OS preferences
      // location: 'top-right' // Set position to top right
    }).showWidget();
  }
  window.addEventListener('load', addDarkmodeWidget);
</script>
</header>
<main id="content">
<header>
<h1 class="title">Fine-tuning GPT with openai API</h1>
<p class="subtitle">Jan 07, 2026</p>
</header>
<section id="outline-container-org81bfecc" class="outline-2">
<h2 id="org81bfecc">Fine tuning GPT-3.5 with openai API</h2>
<div class="outline-text-2" id="text-org81bfecc">
<p>
Here we are going to see how to fine-tune GPT-3.5 using the openai api.  We will
tune GPT-3.5-turbo to learn the content the metadata of a librairy of academic
papers.
</p>
</div>

<div id="outline-container-orgfb7c63a" class="outline-3">
<h3 id="orgfb7c63a">Data formating</h3>
<div class="outline-text-3" id="text-orgfb7c63a">
</div>
<div id="outline-container-org1aa1a3f" class="outline-4">
<h4 id="org1aa1a3f">Create json from xml</h4>
<div class="outline-text-4" id="text-org1aa1a3f">
<p>
The original data comes from mendeley in xml format.  We need to convert it into
a jsonl file.
</p>

<div class="org-src-container">
<pre class="src src-ipython">import xml.etree.ElementTree as ET
import json

def xml_to_jsonl(file_path):
  # Parse XML file
  tree = ET.parse(file_path + '.xml')
  root = tree.getroot()

  # Open the output file and begin writing
  with open(file_path + '.jsonl', 'w') as f:
      # loop over each 'record' in 'records' in XML
      for record in root.find('records').findall('record'):
	  # strip() is used to remove leading and trailing whitespace (like \n)
	  authors = [author.text.strip() for author in record.findall('contributors/authors/author')]
	  title = record.find('titles/title').text.strip() if record.find('titles/title') is not None else 'NA'
	  year = record.find('dates/year').text.strip() if record.find('dates/year') is not None else 'NA'
	  abstract = record.find('abstract').text.strip() if record.find('abstract') is not None else 'NA'
	  journal = record.find('periodical/full-title').text.strip() if record.find('periodical/full-title') is not None else 'NA'

	  # create the 'reference' field
	  if authors:
	      if len(authors) == 1:
		  reference = f"{authors[0]}, {year}"
	      elif len(authors) == 2:
		  reference = f"{authors[0]} &amp; {authors[1]}, {year}"
	      else:
		  reference = f"{authors[0]} et al., {year}"
	  else:
	      reference = 'NA'

	  record_data = {
	      "authors": authors,
	      "title": title,
	      "year": year,
	      "abstract": abstract,
	      "journal": journal,
	      "reference": reference  # add the 'reference' field here
	  }

	  # Each record_data is now written to a new line in the output file
	  f.write(json.dumps(record_data) + '\n')

  print(file_path + '.xml has been successfully converted into .jsonl')
</pre>
</div>

<p>
Let&rsquo;s call the function
</p>
<div class="org-src-container">
<pre class="src src-ipython">path = "/home/leon/Projects/NeuroBot/data/"
file_name = "compte_lab"
file_path = path + file_name

xml_to_jsonl(file_path)
</pre>
</div>
</div>
</div>

<div id="outline-container-org740988c" class="outline-4">
<h4 id="org740988c">Data Splitting</h4>
<div class="outline-text-4" id="text-org740988c">
<p>
We need to split the data to check the model performance on unseen data.
</p>

<div class="org-src-container">
<pre class="src src-ipython">from sklearn.model_selection import train_test_split

train_size = 0.8 
test_size = 0.5 

with open(file_path + '.jsonl', 'r') as f:
    data = [json.loads(line) for line in f]

# # Split data into training and the remaining
train_data, remaining = train_test_split(data, train_size=train_size, shuffle=True, random_state=1)

# # Split remaining data into validation and test data
validation_data, test_data = train_test_split(remaining, train_size=test_size, shuffle=True, random_state=1)

# Write training data to JSON Lines file
with open(file_path + '_train.jsonl', 'w') as f:
    for item in train_data:
	f.write(json.dumps(item) + "\n")

# Write validation data to JSON Lines file
with open(file_path + '_validation.jsonl', 'w') as f:
    for item in validation_data:
	f.write(json.dumps(item) + "\n")

# Write test data to JSON Lines file
with open(file_path + '_test.jsonl', 'w') as f:
    for item in test_data:
	f.write(json.dumps(item) + "\n")

</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-orgee2f436" class="outline-3">
<h3 id="orgee2f436">Creating a conversational chat</h3>
<div class="outline-text-3" id="text-orgee2f436">
<p>
A essential element of fine-tuning a model is to define a proper conversation on which to train GPT
Here, we will ask gpt to try to infer the key points of a given paper based on its abstract.
</p>

<p>
First, we provide GPT with the metadata of a given article based on its reference (Author et al, year).
Then we ask him to infer the main topics/findings of the article.
</p>

<p>
For that we will use the following jsonl conversation message:
</p>
<pre class="example" id="orga2be7ee">
[
{"role": "system", "content": "You are a helpful assistant."},
{"role": "user", "content": f'Give me a brief overview of "{title}".'},
{"role": "assistant", "content": f'Title: "{title}". Authors: {authors}. Published in: {journal} on {year}. Abstract: {abstract}'},
{"role": "user", "content": f'Based on its abstract, what is the main topic of "{title}"?'},
{"role": "assistant", "content": f'The main topic of "{title}" is ...'}, 
{"role": "user", "content": f'What are the key findings as per the abstract of "{title}"?'},
{"role": "assistant", "content": f'The key findings of "{title}" are ...'},  
{"role": "user", "content": f'What methodology is described in the abstract of "{title}"?'},
{"role": "assistant", "content": f'The methodology described in "{title}" is ...'}, 
]
</pre>

<p>
Now let&rsquo;s write a function that creates the chat:
</p>
<div class="org-src-container">
<pre class="src src-ipython">def create_chat_format(file_name):
    with open(file_name, 'r') as f:
	data = [json.loads(line) for line in f]

    chat_format_data = []

    for item in data:
	authors = ", ".join(item['authors'])
	title = item['title']
	year = item['year']
	abstract = item['abstract']
	journal = item['journal']
	reference = item['reference']

	conversation = {
	    'messages': [
		{"role": "system", "content": "You are a helpful assistant."},
		{"role": "user", "content": f'Give me a brief overview of "{reference}".'},
		{"role": "assistant", "content": f'Reference: "{reference}". Authors: {authors}. Published in: {journal} on {year}. Abstract: {abstract}'},
		{"role": "user", "content": f'Based on its abstract, what is the main topic of "{reference}"?'},
		{"role": "assistant", "content": f'The main topic of "{reference}" is ...'}, 
		{"role": "user", "content": f'What are the key findings as per the abstract of "{reference}"?'},
		{"role": "assistant", "content": f'The key findings of "{reference}" are ...'},  
		{"role": "user", "content": f'What methodology is described in the abstract of "{reference}"?'},
		{"role": "assistant", "content": f'The methodology described in "{reference}" is ...'}, 
	    ]
	}

	chat_format_data.append(conversation)

    return chat_format_data
</pre>
</div>

<p>
We finally write the chat back to a jsonl file.
</p>

<div class="org-src-container">
<pre class="src src-ipython">def write_chat_format_file(data, output_file):
    with open(output_file, 'w') as f:
	for conversation in data:
	    f.write(json.dumps(conversation) + "\n")
</pre>
</div>

<p>
Altogether:
</p>

<div class="org-src-container">
<pre class="src src-ipython"># Convert and save data
chat_format_data = create_chat_format(file_path + '_train.jsonl')
# file_path + '_chat.jsonl' is your new file which can be used for training the model
write_chat_format_file(chat_format_data, file_path + '_chat.jsonl')
</pre>
</div>
</div>

<div id="outline-container-org018cf31" class="outline-4">
<h4 id="org018cf31">Upload the training data</h4>
<div class="outline-text-4" id="text-org018cf31">
<p>
Now, we need to upload our chat formated training data to the openai servers:
</p>

<div class="org-src-container">
<pre class="src src-ipython">import os
import openai
openai.api_key = os.getenv("OPENAI_API_KEY")
openai_file = openai.File.create(file=open(file_path + "_chat.jsonl", "rb"), purpose='fine-tune')
</pre>
</div>

<p>
We will then tune a model using the file id:
</p>

<div class="org-src-container">
<pre class="src src-ipython">print(openai_file.id)
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org9136df8" class="outline-3">
<h3 id="org9136df8">Fine-tuning GPT</h3>
<div class="outline-text-3" id="text-org9136df8">
</div>
<div id="outline-container-org9e0bfa0" class="outline-4">
<h4 id="org9e0bfa0">Creating a job</h4>
<div class="outline-text-4" id="text-org9e0bfa0">
<p>
In this example, we will fine-tune gpt-3.5-turbo (but we could have used
babbage-002, davinci-002, or an existing fine-tuned model) by providing the file
ID that was returned when the training data was uploaded to the OpenAI API.
Note: you can customize your fine-tuned model&rsquo;s name using the suffix parameter.
</p>

<div class="org-src-container">
<pre class="src src-ipython">openai.FineTuningJob.create(training_file=openai_file.id, model="gpt-3.5-turbo")
</pre>
</div>
<p>
:RESULTS:
</p>
</div>
</div>

<div id="outline-container-org01225a5" class="outline-4">
<h4 id="org01225a5">Checking a job&rsquo;s status</h4>
<div class="outline-text-4" id="text-org01225a5">
<p>
We can check the job status with
</p>
<div class="org-src-container">
<pre class="src src-ipython">my_jobs = openai.FineTuningJob.list(limit=1)
my_job_id = my_jobs.data[0].id
print(my_jobs.data[0].status)
</pre>
</div>
</div>
</div>

<div id="outline-container-org8fd4293" class="outline-4">
<h4 id="org8fd4293">Asking other queries</h4>
<div class="outline-text-4" id="text-org8fd4293">
<div class="org-src-container">
<pre class="src src-ipython"># List 10 fine-tuning jobs openai.FineTuningJob.list(limit=10)

# Retrieve the state of a fine-tune openai.FineTuningJob.retrieve(my_job_id)

# Cancel a job openai.FineTuningJob.cancel(my_job_id)

# List up to 10 events from a fine-tuning job
openai.FineTuningJob.list_events(id=my_job_id, limit=10)

# Delete a fine-tuned model (must be an owner of the org the model was created in)
openai.Model.delete("ft:gpt-3.5-turbo:acemeco:suffix:abc123")
</pre>
</div>
</div>
</div>
</div>

<div id="outline-container-org3225112" class="outline-3">
<h3 id="org3225112">Using our fine-tuned model</h3>
<div class="outline-text-3" id="text-org3225112">
<p>
We can use our fine-tune model from the openai website or from the api like this:
</p>

<div class="org-src-container">
<pre class="src src-ipython">completion = openai.ChatCompletion.create(
    model="ft:gpt-3.5-turbo-0613:personal::85siq2GE",
    messages=[
	{"role": "system", "content": "You are a helpful assistant."},
	{"role": "user", "content": "Based on the study from Barraclough D, Conroy M, Lee D, Nature Neuroscience 2018? Can you propose a follow up project?"}
    ]
)
print(completion.choices[0].message)
</pre>
</div>

<p>
Facing ChatGPT or even GPT4 with the same prompts, one sees how helpful fine-tuning can be.
</p>

<p>
GPT4
</p>
<pre class="example" id="org4a1fe20">
As an AI assistant, I'm unable to access real-time databases or specific reference materials like Barraclough D, Conroy M, Lee D, Nature Neuroscience 2018 directly. However, based on a generic understanding of another related topic, here's an idea for a generic follow-up project:

Assuming the study was about neural coding and decision making in primate cerebral cortex, a potential follow-up study could aim to understand how these decisions are affected by altering neural activity in specific cortical regions. This could use methods like optogenetics or chemogenetics to selectively manipulate neurons during decision-making tasks, helping to establish causal links between cortical activity and behavioral outcomes.

Remember to always design follow-up projects based on the questions and gaps left by the previous research. These would provide more specific and accurate directions for a new project.
</pre>

<p>
GPT3.5-turbo
</p>
<pre class="example" id="org9c8b265">
Based on the findings of the study by Barraclough, Conroy, and Lee in Nature Neuroscience 2018, a possible follow-up project could be to investigate the long-term effects of the observed neural changes.
</pre>
</div>
</div>
</section>
</main>
<footer id="postamble" class="status">
<p>Last updated 07 Jan. 2026. Built with <a href="https://www.gnu.org/software/emacs/">Emacs</a> 27.2 (<a href="https://orgmode.org">Org</a> mode 9.4.4). <a href="/README.html">Details</a>.</p>
</footer>
</body>
</html>
